<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<configuration>
    <!--HDFS
    NameNode和DataNode目录安置在somebottle用户默认目录下-->
    <property>
        <name>dfs.namenode.name.dir</name>
        <value>file:///root/hdfs/name</value>
        <description>NameNode directory for namespace and transaction logs storage.</description>
    </property>
    <property>
        <name>dfs.datanode.data.dir</name>
        <value>file:///root/hdfs/data</value>
        <description>DataNode directory</description>
    </property>
    <property>
        <name>dfs.replication</name>
        <value>%%HDFS_REPLICATION%%</value>
    </property>
    <property>
        <!--
            取消DataNode节点所在主机的主机名（DNS）与对应IP地址的检查机制，
            防止DataNode分裂。  

            参考： https://zhuanlan.zhihu.com/p/463682863
        -->
        <name>dfs.namenode.datanode.registration.ip-hostname-check</name>
        <value>false</value>
    </property>

    @#HA_CONF_START#@
    <!-- @#HA_CONF_START#@ 和 @#HA_CONF_END#@ 包裹的是高可用配置-->
    <property>
        <name>dfs.nameservices</name>
        <value>%%HDFS_NAMESERVICE%%</value>
        <description>指定hdfs的nameservice,需要和core-site.xml中保持一致</description>
    </property>
    <property>
        <name>dfs.ha.namenodes.%%HDFS_NAMESERVICE%%</name>
        <value>%%HDFS_NAMENODE_NAMES%%</value>
        <description>配置集群中namenode的逻辑名，逗号分隔多个</description>
    </property>
    <!-- 
        @#HA_REPEAT_配置标识_START#@ @#HA_REPEAT_配置标识_END#@ 
        包裹的是可重复配置项，这里用于实现对不同namenode进行配置
    -->
    @#HA_REPEAT_NAMENODE_START#@
    <property>
        <name>dfs.namenode.rpc-address.%%HDFS_NAMESERVICE%%.%%NAMENODE_NAME%%</name>
        <value>%%NAMENODE_HOST%%:8020</value>
        <description>namenode的RPC通信地址</description>
    </property>
    <property>
        <name>dfs.namenode.http-address.%%HDFS_NAMESERVICE%%.%%NAMENODE_NAME%%</name>
        <value>%%NAMENODE_HOST%%:9870</value>
        <description>namenode的Web UI</description>
    </property>
    @#HA_REPEAT_NAMENODE_END#@

    <property>
        <name>dfs.namenode.shared.edits.dir</name>
        <value>qjournal://%%JOURNALNODE_NODES%%/%%HDFS_NAMESERVICE%%</value>
        <description>指定NameNode的edits元数据的共享存储位置（JournalNode RPC地址列表，逗号分隔）</description>
    </property>
    <property>
        <name>dfs.journalnode.edits.dir</name>
        <value>/root/hdfs/journal</value>
        <description>指定JournalNode在本地磁盘数据的位置</description>
    </property>

    <property>
        <name>dfs.ha.automatic-failover.enabled</name>
        <value>true</value>
        <description>开启NameNode故障自动转移</description>
    </property>
    <property>
        <name>dfs.client.failover.proxy.provider.%%HDFS_NAMESERVICE%%</name>
        <value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
        <description>失败后自动转移的实现方式</description>
    </property>
    <property>
        <name>dfs.ha.fencing.methods</name>
        <value>sshfence</value>
        <description>防止脑裂</description>
    </property>
    <property>
        <name>dfs.ha.fencing.ssh.private-key-files</name>
        <value>/root/.ssh/id_rsa</value>
        <description>使用sshfence隔离机制时, 需要ssh密钥，且要求能免密登录</description>
    </property>
    @#HA_CONF_END#@
    
</configuration>