version: '3'

services:
  haspark-main:
    image: somebottle/haspark:3.2.0
    hostname: shmain
    env_file: ./conf.env
    environment:
      - SPARK_MODE=master
    volumes:
      - haspark-hdfs-shmain-name:/root/hdfs/name # namenode数据
      - haspark-hdfs-shmain-journal:/root/hdfs/journal
      - haspark-hdfs-shmain-data:/root/hdfs/data
      - ~/docker/spark/share:/opt/share # 三个容器映射到相同的共享目录
    ports:
      - '8080:8080'
      - '8088:8088'
      - '4040:4040'
      - '8042:8042'
      - '9870:9870'
      - '19888:19888'
  haspark-worker-1:
    image: somebottle/haspark:3.2.0
    hostname: shworker1
    env_file: ./conf.env
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://shmain:7077
      - SPARK_WORKER_MEMORY=1G
      - SPARK_WORKER_CORES=1
    volumes:
      - ~/docker/spark/share:/opt/share
      - haspark-hdfs-worker1-name:/root/hdfs/name # namenode数据
      - haspark-hdfs-worker1-journal:/root/hdfs/journal
      - haspark-hdfs-worker1-data:/root/hdfs/data # datanode数据
    ports:
      - '8081:8081'
  haspark-worker-2:
    image: somebottle/haspark:3.2.0
    hostname: shworker2
    env_file: ./conf.env
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://shmain:7077
      - SPARK_WORKER_MEMORY=1G
      - SPARK_WORKER_CORES=1
    volumes:
      - ~/docker/spark/share:/opt/share
      - haspark-hdfs-worker2-name:/root/hdfs/name # namenode数据
      - haspark-hdfs-worker2-journal:/root/hdfs/journal
      - haspark-hdfs-worker2-data:/root/hdfs/data # datanode数据
    ports:
      - '8082:8081'
      - '8089:8088'
      - '9871:9870'

volumes:
  haspark-hdfs-shmain-name:
  haspark-hdfs-shmain-data:
  haspark-hdfs-shmain-journal:
  haspark-hdfs-worker1-name:
  haspark-hdfs-worker1-data:
  haspark-hdfs-worker1-journal:
  haspark-hdfs-worker2-name:
  haspark-hdfs-worker2-data:
  haspark-hdfs-worker2-journal: